import os
import numpy as np
from openai import OpenAI
from django.conf import settings
import json
import httpx
import logging

logger = logging.getLogger(__name__)

# --------------------------
# Lazy-load SBERT ëª¨ë¸ ê´€ë¦¬
# --------------------------
from sentence_transformers import SentenceTransformer
_sbert_model = None  # ì „ì—­ ë³€ìˆ˜ (ì²˜ìŒì—” None)

def get_sbert_model():
    """SBERT ëª¨ë¸ì„ ì²˜ìŒ ì‚¬ìš©í•  ë•Œë§Œ ë¡œë“œí•˜ë„ë¡ ì„¤ì •"""
    global _sbert_model
    if _sbert_model is None:
        model_path = getattr(settings, 'SBERT_MODEL_PATH', os.path.join(os.getcwd(), "backend", "output", "my_sbert_model"))
        logger.info(f"ğŸ“¦ Loading SBERT model from: {model_path}")
        try:
            _sbert_model = SentenceTransformer(model_path)
        except Exception as e:
            logger.error(f"âš ï¸ Error loading SBERT model from {model_path}: {e}")
            # ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ëª¨ë¸ë¡œ ëŒ€ì²´
            _sbert_model = SentenceTransformer("all-MiniLM-L6-v2")
            logger.info("âœ… Fallback: Loaded default 'all-MiniLM-L6-v2' model")
    return _sbert_model


# --------------------------
# ì„ë² ë”© ìƒì„±
# --------------------------
def generate_embedding(text: str):
    """í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ë°›ì•„ SBERT ì„ë² ë”© ë²¡í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not text:
        return None
    try:
        model = get_sbert_model()
        embeddings = model.encode(text, convert_to_tensor=False)
        return embeddings.tolist()
    except Exception as e:
        logger.error(f"âŒ Error generating embedding: {e}")
        return None


# --------------------------
# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
# --------------------------
def calculate_similarity(embedding1: list, embedding2: list):
    """ë‘ ì„ë² ë”© ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°"""
    if not embedding1 or not embedding2:
        return 0.0
    try:
        vec1 = np.array(embedding1)
        vec2 = np.array(embedding2)
        similarity = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
        return float(similarity)
    except Exception as e:
        logger.error(f"Error calculating similarity: {e}")
        return 0.0


# --------------------------
# OpenAI ê¸°ë°˜ ë§¤ì¹­ ì„¤ëª… ìƒì„±
# --------------------------
def generate_match_explanation(user_data: dict, project_data: dict, similarity_score: float):
    """OpenAI APIë¡œ ë§¤ì¹­ ë¶„ì„ ë° ì„¤ëª… ìƒì„±"""
    api_key = os.getenv("OPENAI_API_KEY") or getattr(settings, 'OPENAI_API_KEY', None)
    if not api_key:
        logger.warning("OPENAI_API_KEY is not set.")
        return None

    client = OpenAI(api_key=api_key, http_client=httpx.Client(trust_env=False))

    user_info_str = json.dumps(user_data, ensure_ascii=False, indent=2)
    project_info_str = json.dumps(project_data, ensure_ascii=False, indent=2)

    prompt = f"""ì‚¬ìš©ì í”„ë¡œí•„ê³¼ í”„ë¡œì íŠ¸ ì •ë³´ê°€ ì£¼ì–´ì§€ë©´, ì´ ë‘˜ì˜ ì „ë°˜ì ì¸ ë§¤ì¹­ë¥ ì´ {similarity_score:.0f}%ì¸ ì´ìœ ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

[ë¶„ì„ ê¸°ì¤€]
1. ê¸°ìˆ  ë§¤ì¹­: ì‚¬ìš©ìì˜ ê¸°ìˆ  ìŠ¤íƒê³¼ í”„ë¡œì íŠ¸ì˜ ê¸°ìˆ  ìŠ¤íƒì˜ ì¼ì¹˜ë„ë¥¼ í‰ê°€ (100ì  ë§Œì )
2. ì„±í–¥ ì í•©ë„: ì‚¬ìš©ìì˜ í˜‘ì—… ìŠ¤íƒ€ì¼, ì„ í˜¸ ì£¼ì œ ë“±ê³¼ í”„ë¡œì íŠ¸ì˜ íŠ¹ì„±ì˜ ì¼ì¹˜ë„ë¥¼ í‰ê°€ (100ì  ë§Œì )
3. ê²½í—˜ ìˆ˜ì¤€: ì‚¬ìš©ìì˜ ì „ê³µ, ìˆ™ë ¨ë„ì™€ í”„ë¡œì íŠ¸ì˜ ì—°ê´€ì„±ì„ í‰ê°€ (100ì  ë§Œì )
4. ì¢…í•© ì„¤ëª…: ìœ„ ì„¸ë¶€ ì ìˆ˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì™œ ì´ëŸ° ì ìˆ˜ê°€ ë‚˜ì™”ëŠ”ì§€ ì¢…í•©ì ìœ¼ë¡œ 2-3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª….

[ì‚¬ìš©ì ì •ë³´]
{user_info_str}

[í”„ë¡œì íŠ¸ ì •ë³´]
{project_info_str}

[ì¶œë ¥ í˜•ì‹]
ë°˜ë“œì‹œ ì•„ë˜ì™€ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
{{
  "tech_score": <ê¸°ìˆ  ë§¤ì¹­ ì ìˆ˜ (0-100 ì‚¬ì´ ì •ìˆ˜)>,
  "personality_score": <ì„±í–¥ ì í•©ë„ ì ìˆ˜ (0-100 ì‚¬ì´ ì •ìˆ˜)>,
  "experience_score": <ê²½í—˜ ìˆ˜ì¤€ ì ìˆ˜ (0-100 ì‚¬ì´ ì •ìˆ˜)>,
  "explanation": "<ì¢…í•© ì„¤ëª… í…ìŠ¤íŠ¸>"
}}
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a helpful assistant that analyzes userâ€“project match and returns JSON only."},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"},
            temperature=0.5
        )
        result_json = json.loads(response.choices[0].message.content)
        return result_json
    except Exception as e:
        logger.error(f"Error generating match explanation with OpenAI API: {e}")
        return None


# --------------------------
# Match Service
# --------------------------
from teamspace.models import User, Projects, UserEmbedding, ProjectEmbedding, MatchScores

class MatchService:
    """ì‚¬ìš©ìì™€ í”„ë¡œì íŠ¸ ë§¤ì¹­ ì ìˆ˜ ë° ì¶”ì²œ ë¡œì§"""
    @staticmethod
    def get_or_create_match_score(user: User, project: Projects):
        logger.info(f"ğŸ” Calculating match score for user {user.email} and project {project.title}")
        match_score_entry, created = MatchScores.objects.get_or_create(
            user=user, project=project,
            defaults={'score': 0.0, 'explanation': ''}
        )

        # ê¸°ì¡´ ë°ì´í„°ê°€ ìœ íš¨í•˜ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        if not created and match_score_entry.explanation and match_score_entry.score != 0.0:
            return match_score_entry

        # ì„ë² ë”© í™•ì¸
        try:
            user_embedding_obj = UserEmbedding.objects.get(user=user)
            project_embedding_obj = ProjectEmbedding.objects.get(project=project)
        except (UserEmbedding.DoesNotExist, ProjectEmbedding.DoesNotExist):
            match_score_entry.score = 0.0
            match_score_entry.explanation = "ì„ë² ë”©ì´ ìƒì„±ë˜ì§€ ì•Šì•„ ë§¤ì¹­ ì ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            match_score_entry.save()
            return match_score_entry

        user_embedding = user_embedding_obj.embedding
        project_embedding = project_embedding_obj.embedding

        # ìœ ì‚¬ë„ ê³„ì‚°
        if user_embedding and project_embedding:
            score = calculate_similarity(user_embedding, project_embedding) * 100
            match_score_entry.score = round(score, 2)

            user_data = {
                "major": user.major,
                "specialty": user.specialty,
                "tech_stack": user.tech_stack,
                "experience_level": user.experience_level,
                "preferred_project_topics": user.preferred_project_topics,
                "collaboration_style": user.collaboration_style,
                "belbin_role": user.belbin_role,
            }
            project_data = {
                "title": project.title,
                "description": project.description,
                "goal": project.goal,
                "tech_stack": project.tech_stack,
            }

            explanation_data = generate_match_explanation(user_data, project_data, match_score_entry.score)
            if explanation_data:
                match_score_entry.tech_score = explanation_data.get("tech_score", 0)
                match_score_entry.personality_score = explanation_data.get("personality_score", 0)
                match_score_entry.experience_score = explanation_data.get("experience_score", 0)
                match_score_entry.explanation = explanation_data.get("explanation", "ì„¤ëª…ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                match_score_entry.explanation = "ë§¤ì¹­ ë¶„ì„ ë°ì´í„° ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        else:
            match_score_entry.score = 0.0
            match_score_entry.explanation = "ì„ë² ë”© ë°ì´í„°ê°€ ìœ íš¨í•˜ì§€ ì•Šì•„ ë§¤ì¹­ ì ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        match_score_entry.save()
        return match_score_entry

    @staticmethod
    def get_user_project_match(user: User, project: Projects):
        """íŠ¹ì • ì‚¬ìš©ìì™€ í”„ë¡œì íŠ¸ì˜ ë§¤ì¹­ ê²°ê³¼ ë°˜í™˜ (ì—†ìœ¼ë©´ ìƒˆë¡œ ê³„ì‚°)"""
        return MatchService.get_or_create_match_score(user, project)

    @staticmethod
    def get_recommended_projects(user: User):
        """AI ê¸°ë°˜ í”„ë¡œì íŠ¸ ì¶”ì²œ"""
        all_projects = Projects.objects.filter(is_open=True)
        recommended_projects_data = []

        for project in all_projects:
            match_score_entry = MatchService.get_or_create_match_score(user, project)
            recommended_projects_data.append({
                'project': project,
                'score': match_score_entry.score,
                'explanation': match_score_entry.explanation
            })

        recommended_projects_data.sort(key=lambda x: x['score'], reverse=True)
        return recommended_projects_data
